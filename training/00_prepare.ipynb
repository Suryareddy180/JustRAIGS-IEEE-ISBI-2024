{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5284c696-f45b-4522-be05-c1d9e9e51693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19a39f41-84e3-4db2-95bc-9de57481e5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101423"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path_list = glob.glob('JustRAIGS/images/*.*')\n",
    "len(image_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a7c00e4-272e-484b-9310-f950271da9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101423"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('JustRAIGS_Train_labels.csv', sep=';')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a513bb02-dabd-40cd-a231-7eda8a9ec45e",
   "metadata": {},
   "source": [
    "# Generating Unique Patient IDs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab667e59-99ad-49d0-ab13-341bc06bbc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 101423/101423 [23:27<00:00, 72.04it/s]\n"
     ]
    }
   ],
   "source": [
    "exception_count = 0\n",
    "df['generated_patient_id'] = -1\n",
    "for idx, row in tqdm.tqdm(df.iterrows(), total=len(df)):\n",
    "    fellow_eye_id = row['Fellow Eye ID']\n",
    "    try:\n",
    "        if df[df['Eye ID'] == fellow_eye_id]['generated_patient_id'].values[0] == -1:\n",
    "            df.loc[idx, 'generated_patient_id'] = idx\n",
    "            # print('idx', idx)\n",
    "            df.loc[df['Eye ID'] == fellow_eye_id, 'generated_patient_id'] = idx\n",
    "    except Exception as e:\n",
    "        exception_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe83d0d-44eb-4a59-80e0-481ee2dcc2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9101it [00:04, 2058.65it/s]\n"
     ]
    }
   ],
   "source": [
    "next_id = df['generated_patient_id'].max()+1\n",
    "for idx, row in tqdm.tqdm(df[df['generated_patient_id'] == -1].iterrows()):\n",
    "    df.loc[idx, 'generated_patient_id'] = next_id\n",
    "    next_id = df['generated_patient_id'].max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "823a2eb3-531c-4a07-b7c1-8c9bc5bf2e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.835311787485071"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(list(df['generated_patient_id']), return_counts=True)[1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "707d64b4-8820-4b79-8a70-0073044d1d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['filename'] = [f.split(os.sep)[-1] for f in image_path_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e9eb424-c0ef-4779-a70a-d382bb8bbece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['path'] = [os.path.join('JustRAIGS/images/', f.split(os.sep)[-1]) for f in image_path_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23be6bce-ee3f-4147-ba10-bf5b7187a64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df[~df['generated_patient_id'].isna()]) == len(image_path_list)\n",
    "assert len(image_path_list) == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5efc69b3-a3d4-4ca6-a287-6613a221615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prepared df\n",
    "df.to_csv('JustRAIGS_Train_labels_PREPARED.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3acda15-5e79-4b1e-948c-5622faea3939",
   "metadata": {},
   "source": [
    "# Soft Label Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd4ff668-a4bb-4ef7-bd87-720e55f2664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('JustRAIGS_Train_labels_PREPARED.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af8ef14-617d-4fba-88b6-2d46a5ffc9f5",
   "metadata": {},
   "source": [
    "# Transform GT labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d801a78-53a8-47bc-ad41-c86434aabefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_consensus(g1, g2, g3):\n",
    "    if g1 == g2:\n",
    "        consensus = g1\n",
    "    else:\n",
    "        consensus = g3\n",
    "\n",
    "    if consensus == 'U':\n",
    "        consensus = g3\n",
    "    return consensus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9a7680-8525-497f-84d5-4f92d27632df",
   "metadata": {},
   "source": [
    "## Final Label, STR -> INT mapping\n",
    "'NRG': 0<br>\n",
    "'RG' : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef08ffc9-d627-44f3-ae87-8caee572612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_target_mapping =  {'NRG': 0, 'RG' : 1, }\n",
    "df['Final Label'] = df['Final Label'].replace(ref_target_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c0c062-1b12-474c-b693-748b2343ce94",
   "metadata": {},
   "source": [
    "## Final Label, smooth mapping\n",
    "smooth label = (positive assesments) / (number of assesments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbbf67ea-077e-470d-a2ff-dd7d371b99c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smooth_label_consensus(g1, g2, g3):\n",
    "    RG_count = 0\n",
    "    valid_label_count = 0\n",
    "    \n",
    "    for v in [g1, g2, g3]:\n",
    "        if v == 'RG':\n",
    "            RG_count += 1\n",
    "\n",
    "        if v == 'RG' or v == 'NRG':\n",
    "            valid_label_count += 1\n",
    "    \n",
    "    consensus = RG_count / valid_label_count\n",
    "    return consensus\n",
    "    \n",
    "header_g1 = 'Label G1'\n",
    "header_g2 = 'Label G2'\n",
    "header_g3 = 'Label G3'\n",
    "\n",
    "df['Smooth Final Label'] = df.apply(lambda x: get_smooth_label_consensus(x[header_g1], x[header_g2], x[header_g3]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3578c99-7a07-4a6c-8845-33d3c3f5da12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0, 0.3333333333333333, 0.5, 0.6666666666666666, 1.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['Smooth Final Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3543dc0-fb74-402e-89b6-bac6ce5524ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Smooth Final Label\n",
       "0.000000    94753\n",
       "0.333333     3220\n",
       "1.000000     2663\n",
       "0.666667      554\n",
       "0.500000      233\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts('Smooth Final Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8216087-502e-493f-a630-840d70bd90fb",
   "metadata": {},
   "source": [
    "## Justification Labels, eval mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd239278-5b0b-4fa2-b520-c1f3fa4b1012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_loss(true_labels, predicted_labels):\n",
    "    \"\"\"Calculate the Hamming loss for the given true and predicted labels.\"\"\"\n",
    "    # Convert to numpy arrays for efficient computation\n",
    "    true_labels = np.array(true_labels)\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "    # Calculate the hamming distance that is basically the total number of mismatches\n",
    "    Hamming_distance = np.sum(np.not_equal(true_labels, predicted_labels))\n",
    "    print(\"Hamming distance\", Hamming_distance)\n",
    "    \n",
    "    # Calculate the total number of labels\n",
    "    total_corrected_labels= true_labels.size\n",
    "\n",
    "    # Compute the Modified Hamming loss\n",
    "    loss = Hamming_distance / total_corrected_labels\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8115a426-bdc8-4229-9799-a43c729ad047",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_label_columns = ['G1 ANRS', 'G1 ANRI', 'G1 RNFLDS', 'G1 RNFLDI', 'G1 BCLVS', 'G1 BCLVI', 'G1 NVT', 'G1 DH', 'G1 LD', 'G1 LC']\n",
    "G2_label_columns = ['G2 ANRS', 'G2 ANRI', 'G2 RNFLDS', 'G2 RNFLDI', 'G2 BCLVS', 'G2 BCLVI', 'G2 NVT', 'G2 DH', 'G2 LD', 'G2 LC']\n",
    "G3_label_columns = ['G3 ANRS', 'G3 ANRI', 'G3 RNFLDS', 'G3 RNFLDS', 'G3 BCLVS', 'G3 BCLVI', 'G3 NVT', 'G3 DH', 'G3 LD', 'G3 LC']\n",
    "\n",
    "# Just for checking on training dataset\n",
    "#---------------------------------------\n",
    "pred_labels=[1,1,0,0,0,0,0,0,1,1]\n",
    "\n",
    "#pred_labels=[1,0,1,0,1,0,1,0,0,1]\n",
    "#----------------------------------------\n",
    "\n",
    "\n",
    "# If grader 3 labels are prsent evalution check\n",
    "# row = df.loc[100]\n",
    "\n",
    "# for grader 1 and 2, there is no grader 3\n",
    "# row = df.loc[34]\n",
    "\n",
    "def get_justification_labels_for_eval(row):\n",
    "    G1_labels = row[G1_label_columns].values.tolist()\n",
    "    G2_labels = row[G2_label_columns].values.tolist()\n",
    "    G3_labels = row[G3_label_columns].values.tolist()\n",
    "    \n",
    "    if (row['Final Label'] == 'RG') or (row['Final Label'] == 1):\n",
    "        if row['Label G3'] == 'RG':\n",
    "            true_justification_labels = G3_labels\n",
    "        else:\n",
    "            # G1(j) != G2(j) -> 0\n",
    "\n",
    "            # find features which have disaggrement\n",
    "            disagreed_features = np.not_equal(G1_labels, G2_labels)\n",
    "            \n",
    "            # Select specific columns where disagreed_features is True\n",
    "            true_justification_labels = np.array(G2_labels)\n",
    "            true_justification_labels[disagreed_features] = 0\n",
    "\n",
    "    else:\n",
    "        return np.zeros(len(G1_label_columns))\n",
    "\n",
    "    return true_justification_labels\n",
    "\n",
    "\n",
    "def get_justification_labels_for_training_smooth(row, justification_for_positive_only=True):\n",
    "    G1_labels = row[G1_label_columns].values.tolist()\n",
    "    G2_labels = row[G2_label_columns].values.tolist()\n",
    "    G3_labels = row[G3_label_columns].values.tolist()\n",
    "    \n",
    "    if (not justification_for_positive_only) or ((row['Final Label'] == 'RG') or (row['Final Label'] == 1)):\n",
    "        true_justification_labels = np.nanmean(np.array([G1_labels, G2_labels, G3_labels]), 0)\n",
    "\n",
    "    else:\n",
    "        true_justification_labels = np.zeros(len(G1_label_columns))\n",
    "\n",
    "    return true_justification_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58c711c1-a748-4171-b366-883eb0c32eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval ANRS\n",
      "Eval ANRI\n",
      "Eval RNFLDS\n",
      "Eval RNFLDI\n",
      "Eval BCLVS\n",
      "Eval BCLVI\n",
      "Eval NVT\n",
      "Eval DH\n",
      "Eval LD\n",
      "Eval LC\n",
      "Smooth Only RG ANRS\n",
      "Smooth Only RG ANRI\n",
      "Smooth Only RG RNFLDS\n",
      "Smooth Only RG RNFLDI\n",
      "Smooth Only RG BCLVS\n",
      "Smooth Only RG BCLVI\n",
      "Smooth Only RG NVT\n",
      "Smooth Only RG DH\n",
      "Smooth Only RG LD\n",
      "Smooth Only RG LC\n",
      "Smooth Include NRG ANRS\n",
      "Smooth Include NRG ANRI\n",
      "Smooth Include NRG RNFLDS\n",
      "Smooth Include NRG RNFLDI\n",
      "Smooth Include NRG BCLVS\n",
      "Smooth Include NRG BCLVI\n",
      "Smooth Include NRG NVT\n",
      "Smooth Include NRG DH\n",
      "Smooth Include NRG LD\n",
      "Smooth Include NRG LC\n"
     ]
    }
   ],
   "source": [
    "new_column_data = df.apply(lambda x: \n",
    "                get_justification_labels_for_eval(\n",
    "                    x, \n",
    "                ), axis=1, result_type='expand',\n",
    "               ).rename(\n",
    "    columns={0:'Eval ANRS', \n",
    "             1:'Eval ANRI', \n",
    "             2:'Eval RNFLDS', \n",
    "             3:'Eval RNFLDI', \n",
    "             4:'Eval BCLVS',\n",
    "             5:'Eval BCLVI',\n",
    "             6:'Eval NVT',\n",
    "             7:'Eval DH',\n",
    "             8:'Eval LD',\n",
    "             9:'Eval LC'})\n",
    "for col in new_column_data:\n",
    "    print(col)\n",
    "    df[col] = new_column_data[col]\n",
    "\n",
    "\n",
    "new_column_data = df.apply(lambda x: \n",
    "                get_justification_labels_for_training_smooth(\n",
    "                    x, \n",
    "                    justification_for_positive_only=True\n",
    "                ), axis=1, result_type='expand'\n",
    "               ).rename(\n",
    "    columns={0:'Smooth Only RG ANRS', \n",
    "             1:'Smooth Only RG ANRI', \n",
    "             2:'Smooth Only RG RNFLDS', \n",
    "             3:'Smooth Only RG RNFLDI', \n",
    "             4:'Smooth Only RG BCLVS',\n",
    "             5:'Smooth Only RG BCLVI',\n",
    "             6:'Smooth Only RG NVT',\n",
    "             7:'Smooth Only RG DH',\n",
    "             8:'Smooth Only RG LD',\n",
    "             9:'Smooth Only RG LC'})\n",
    "for col in new_column_data:\n",
    "    print(col)\n",
    "    df[col] = new_column_data[col]\n",
    "\n",
    "new_column_data = df.apply(lambda x: \n",
    "                get_justification_labels_for_training_smooth(\n",
    "                    x, \n",
    "                    justification_for_positive_only=False\n",
    "                ), axis=1, result_type='expand'\n",
    "               ).rename(\n",
    "    columns={0:'Smooth Include NRG ANRS', \n",
    "             1:'Smooth Include NRG ANRI', \n",
    "             2:'Smooth Include NRG RNFLDS', \n",
    "             3:'Smooth Include NRG RNFLDI', \n",
    "             4:'Smooth Include NRG BCLVS',\n",
    "             5:'Smooth Include NRG BCLVI',\n",
    "             6:'Smooth Include NRG NVT',\n",
    "             7:'Smooth Include NRG DH',\n",
    "             8:'Smooth Include NRG LD',\n",
    "             9:'Smooth Include NRG LC'})\n",
    "for col in new_column_data:\n",
    "    print(col)\n",
    "    df[col] = new_column_data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20c6ee17-6536-423b-8ca0-fee875ab2c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Eval ANRS', 'Smooth Only RG ANRS', 'Smooth Include NRG ANRS')\n",
      "('Eval ANRI', 'Smooth Only RG ANRI', 'Smooth Include NRG ANRI')\n",
      "('Eval RNFLDS', 'Smooth Only RG RNFLDS', 'Smooth Include NRG RNFLDS')\n",
      "('Eval RNFLDI', 'Smooth Only RG RNFLDI', 'Smooth Include NRG RNFLDI')\n",
      "('Eval BCLVS', 'Smooth Only RG BCLVS', 'Smooth Include NRG BCLVS')\n",
      "('Eval BCLVI', 'Smooth Only RG BCLVI', 'Smooth Include NRG BCLVI')\n",
      "('Eval NVT', 'Smooth Only RG NVT', 'Smooth Include NRG NVT')\n",
      "('Eval DH', 'Smooth Only RG DH', 'Smooth Include NRG DH')\n",
      "('Eval LD', 'Smooth Only RG LD', 'Smooth Include NRG LD')\n",
      "('Eval LC', 'Smooth Only RG LC', 'Smooth Include NRG LC')\n"
     ]
    }
   ],
   "source": [
    "for cols in zip(\n",
    "    ['Eval ANRS', 'Eval ANRI', 'Eval RNFLDS', 'Eval RNFLDI', 'Eval BCLVS',\n",
    "       'Eval BCLVI', 'Eval NVT', 'Eval DH', 'Eval LD', 'Eval LC',\n",
    "       ],\n",
    "    ['Smooth Only RG ANRS', 'Smooth Only RG ANRI', 'Smooth Only RG RNFLDS',\n",
    "       'Smooth Only RG RNFLDI', 'Smooth Only RG BCLVS', 'Smooth Only RG BCLVI',\n",
    "       'Smooth Only RG NVT', 'Smooth Only RG DH', 'Smooth Only RG LD',\n",
    "       'Smooth Only RG LC', ],\n",
    "    ['Smooth Include NRG ANRS',\n",
    "       'Smooth Include NRG ANRI', 'Smooth Include NRG RNFLDS',\n",
    "       'Smooth Include NRG RNFLDI', 'Smooth Include NRG BCLVS',\n",
    "       'Smooth Include NRG BCLVI', 'Smooth Include NRG NVT',\n",
    "       'Smooth Include NRG DH', 'Smooth Include NRG LD',\n",
    "       'Smooth Include NRG LC'],\n",
    "):\n",
    "    print(cols)\n",
    "    df.loc[(df[cols[0]] == 1) & (df[cols[1]] < 1), cols[1]] = df[cols[0]]\n",
    "    df.loc[(df[cols[0]] == 1) & (df[cols[2]] < 1), cols[2]] = df[cols[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a32d40-f08f-43b4-bb9e-fe26460d4353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prepared df\n",
    "df.to_csv('JustRAIGS_Train_labels_PREPARED.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c348e06-a255-4f90-8dc3-e9890179cc8e",
   "metadata": {},
   "source": [
    "## Label Smoothing Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc5cdfa3-e9a7-46d9-ae8c-47b23d8e69b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Final Label</th>\n",
       "      <th>Label G1</th>\n",
       "      <th>Label G2</th>\n",
       "      <th>Label G3</th>\n",
       "      <th>G1 ANRS</th>\n",
       "      <th>G2 ANRS</th>\n",
       "      <th>G3 ANRS</th>\n",
       "      <th>Eval ANRS</th>\n",
       "      <th>Smooth Only RG ANRS</th>\n",
       "      <th>Smooth Include NRG ANRS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NRG</td>\n",
       "      <td>NRG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0</td>\n",
       "      <td>NRG</td>\n",
       "      <td>RG</td>\n",
       "      <td>NRG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>NRG</td>\n",
       "      <td>U</td>\n",
       "      <td>NRG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>NRG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NRG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>RG</td>\n",
       "      <td>NRG</td>\n",
       "      <td>NRG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>0</td>\n",
       "      <td>RG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NRG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>1</td>\n",
       "      <td>NRG</td>\n",
       "      <td>RG</td>\n",
       "      <td>RG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7119</th>\n",
       "      <td>1</td>\n",
       "      <td>NRG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>1</td>\n",
       "      <td>RG</td>\n",
       "      <td>NRG</td>\n",
       "      <td>RG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>RG</td>\n",
       "      <td>NRG</td>\n",
       "      <td>RG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>1</td>\n",
       "      <td>RG</td>\n",
       "      <td>RG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>RG</td>\n",
       "      <td>RG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>RG</td>\n",
       "      <td>RG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>1</td>\n",
       "      <td>RG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>1</td>\n",
       "      <td>RG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "      <td>U</td>\n",
       "      <td>RG</td>\n",
       "      <td>RG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1</td>\n",
       "      <td>U</td>\n",
       "      <td>RG</td>\n",
       "      <td>RG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Final Label Label G1 Label G2 Label G3  G1 ANRS  G2 ANRS  G3 ANRS  \\\n",
       "0               0      NRG      NRG      NaN      0.0      0.0      NaN   \n",
       "137             0      NRG       RG      NRG      0.0      1.0      0.0   \n",
       "65              0      NRG        U      NRG      0.0      0.0      0.0   \n",
       "33              0      NRG      NaN      NRG      0.0      NaN      0.0   \n",
       "11              0       RG      NRG      NRG      1.0      0.0      0.0   \n",
       "1285            0       RG      NaN      NRG      1.0      NaN      0.0   \n",
       "660             1      NRG       RG       RG      0.0      0.0      1.0   \n",
       "7119            1      NRG      NaN       RG      0.0      NaN      1.0   \n",
       "373             1       RG      NRG       RG      1.0      0.0      0.0   \n",
       "68              1       RG      NRG       RG      1.0      0.0      1.0   \n",
       "701             1       RG       RG      NaN      0.0      1.0      NaN   \n",
       "34              1       RG       RG      NaN      1.0      0.0      NaN   \n",
       "60              1       RG       RG      NaN      1.0      1.0      NaN   \n",
       "2547            1       RG      NaN       RG      1.0      NaN      0.0   \n",
       "2055            1       RG      NaN       RG      1.0      NaN      1.0   \n",
       "348             1        U       RG       RG      0.0      1.0      0.0   \n",
       "122             1        U       RG       RG      0.0      1.0      1.0   \n",
       "188             1      NaN      NaN       RG      NaN      NaN      0.0   \n",
       "646             1      NaN      NaN       RG      NaN      NaN      1.0   \n",
       "\n",
       "      Eval ANRS  Smooth Only RG ANRS  Smooth Include NRG ANRS  \n",
       "0           0.0             0.000000                 0.000000  \n",
       "137         0.0             0.000000                 0.333333  \n",
       "65          0.0             0.000000                 0.000000  \n",
       "33          0.0             0.000000                 0.000000  \n",
       "11          0.0             0.000000                 0.333333  \n",
       "1285        0.0             0.000000                 0.500000  \n",
       "660         1.0             1.000000                 1.000000  \n",
       "7119        1.0             1.000000                 1.000000  \n",
       "373         0.0             0.333333                 0.333333  \n",
       "68          1.0             1.000000                 1.000000  \n",
       "701         0.0             0.500000                 0.500000  \n",
       "34          0.0             0.500000                 0.500000  \n",
       "60          1.0             1.000000                 1.000000  \n",
       "2547        0.0             0.500000                 0.500000  \n",
       "2055        1.0             1.000000                 1.000000  \n",
       "348         0.0             0.333333                 0.333333  \n",
       "122         1.0             1.000000                 1.000000  \n",
       "188         0.0             0.000000                 0.000000  \n",
       "646         1.0             1.000000                 1.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\n",
    "    'Final Label', \n",
    "    'Label G1', 'Label G2','Label G3', \n",
    "    'G1 ANRS', 'G2 ANRS', 'G3 ANRS', \n",
    "    'Eval ANRS', \n",
    "    'Smooth Only RG ANRS',\n",
    "    'Smooth Include NRG ANRS', \n",
    "]].drop_duplicates(\n",
    "    [\n",
    "        'G1 ANRS', 'G2 ANRS', 'G3 ANRS',\n",
    "        'Eval ANRS', \n",
    "        'Smooth Only RG ANRS',\n",
    "        'Smooth Include NRG ANRS', \n",
    "    ]).sort_values(\n",
    "    by=[\n",
    "        'Final Label', \n",
    "        'Label G1', 'Label G2','Label G3', \n",
    "        'G1 ANRS', 'G2 ANRS', 'G3 ANRS',\n",
    "    ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
